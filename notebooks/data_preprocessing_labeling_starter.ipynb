{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import re\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='../logs/data_processing.log',\n",
    "                    level=logging.INFO,\n",
    "                    format='%(asctime)s:%(levelname)s:%(message)s')\n",
    "  \n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../scripts')))\n",
    "from load_data import Load_Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/telegram_data.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for NaN values in the 'Message' column:\n",
      "Number of NaN values in 'Message' column: 1849\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking for NaN values in the 'Message' column:\")\n",
    "nan_count = df['Message'].isnull().sum()\n",
    "print(f\"Number of NaN values in 'Message' column: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after dropping NaN values in 'Message' column: (3166, 6)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['Message'])\n",
    "\n",
    "# Print the shape of the dataset after dropping NaN values in the \"Message\" column\n",
    "print(f\"Dataset shape after dropping NaN values in 'Message' column: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5328.0</td>\n",
       "      <td>💥3pcs silicon brush spatulas\\n\\n\\n      \\n    ...</td>\n",
       "      <td>2024-09-20 11:50:02+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5328.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5327.0</td>\n",
       "      <td>💥Mandoline Slicer\\n\\n👉 ጊዜ ቆጣቢ ስላይስ ማድረጊያ \\n👉  ...</td>\n",
       "      <td>2024-09-20 08:11:40+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5326.0</td>\n",
       "      <td>💥Table Desk Edge Guard Strip\\n       💯 High Qu...</td>\n",
       "      <td>2024-09-20 05:23:18+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5325.0</td>\n",
       "      <td>💥Table Desk Edge Guard Strip\\n       💯 High Qu...</td>\n",
       "      <td>2024-09-20 05:21:14+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5325.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5323.0</td>\n",
       "      <td>💥Only baby 3in1 double bottle milk warmer,ster...</td>\n",
       "      <td>2024-09-19 13:54:46+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5323.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Channel Title    Channel Username      ID  \\\n",
       "5   Sheger online-store  @Shageronlinestore  5328.0   \n",
       "6   Sheger online-store  @Shageronlinestore  5327.0   \n",
       "7   Sheger online-store  @Shageronlinestore  5326.0   \n",
       "8   Sheger online-store  @Shageronlinestore  5325.0   \n",
       "10  Sheger online-store  @Shageronlinestore  5323.0   \n",
       "\n",
       "                                              Message  \\\n",
       "5   💥3pcs silicon brush spatulas\\n\\n\\n      \\n    ...   \n",
       "6   💥Mandoline Slicer\\n\\n👉 ጊዜ ቆጣቢ ስላይስ ማድረጊያ \\n👉  ...   \n",
       "7   💥Table Desk Edge Guard Strip\\n       💯 High Qu...   \n",
       "8   💥Table Desk Edge Guard Strip\\n       💯 High Qu...   \n",
       "10  💥Only baby 3in1 double bottle milk warmer,ster...   \n",
       "\n",
       "                         Date                          Media Path  \n",
       "5   2024-09-20 11:50:02+00:00  photos/@Shageronlinestore_5328.jpg  \n",
       "6   2024-09-20 08:11:40+00:00                                 NaN  \n",
       "7   2024-09-20 05:23:18+00:00                                 NaN  \n",
       "8   2024-09-20 05:21:14+00:00  photos/@Shageronlinestore_5325.jpg  \n",
       "10  2024-09-19 13:54:46+00:00  photos/@Shageronlinestore_5323.jpg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5       💥3pcs silicon brush spatulas\\n\\n\\n      \\n    ...\n",
       "6       💥Mandoline Slicer\\n\\n👉 ጊዜ ቆጣቢ ስላይስ ማድረጊያ \\n👉  ...\n",
       "7       💥Table Desk Edge Guard Strip\\n       💯 High Qu...\n",
       "8       💥Table Desk Edge Guard Strip\\n       💯 High Qu...\n",
       "10      💥Only baby 3in1 double bottle milk warmer,ster...\n",
       "                              ...                        \n",
       "5009    🎯 Kitchen Sticker\\n\\nለኪችንዎ ውበት እጅግ ተመራጭ \\n🔰ውሀ ...\n",
       "5010    🎯 3in1 One Step Hair Dryer & Styler \\n\\n👉 ከርል ...\n",
       "5011    ✅ Home GYM - X5 slimming vibrator \\n\\n📢📢📢 ታላቅ ...\n",
       "5012    ለጤናችን-Health & Personal Care\\n\\n📍FingerTip Pul...\n",
       "5013    #Finger_tip_pulse_oximeter\\n       #በተመጣጣኝ_ዋጋ\\...\n",
       "Name: Message, Length: 3166, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_df=df['Message']\n",
    "message_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Channel Title    Channel Username      ID  \\\n",
      "5   Sheger online-store  @Shageronlinestore  5328.0   \n",
      "6   Sheger online-store  @Shageronlinestore  5327.0   \n",
      "7   Sheger online-store  @Shageronlinestore  5326.0   \n",
      "8   Sheger online-store  @Shageronlinestore  5325.0   \n",
      "10  Sheger online-store  @Shageronlinestore  5323.0   \n",
      "\n",
      "                                              Message  \\\n",
      "5   3pcs silicon brush spatulas\\n\\n\\n      \\n     ...   \n",
      "6   Mandoline Slicer\\n\\n ጊዜ ቆጣቢ ስላይስ ማድረጊያ \\n  ለእጅ...   \n",
      "7   Table Desk Edge Guard Strip\\n        High Qual...   \n",
      "8   Table Desk Edge Guard Strip\\n        High Qual...   \n",
      "10  Only baby 3in1 double bottle milk warmer,steri...   \n",
      "\n",
      "                         Date                          Media Path  \n",
      "5   2024-09-20 11:50:02+00:00  photos/@Shageronlinestore_5328.jpg  \n",
      "6   2024-09-20 08:11:40+00:00                                 NaN  \n",
      "7   2024-09-20 05:23:18+00:00                                 NaN  \n",
      "8   2024-09-20 05:21:14+00:00  photos/@Shageronlinestore_5325.jpg  \n",
      "10  2024-09-19 13:54:46+00:00  photos/@Shageronlinestore_5323.jpg  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example of your DataFrame\n",
    "# df = pd.DataFrame({'Message': ['💥3pcs silicon brush spatulas...', '💥Mandoline Slicer...', ...]})\n",
    "\n",
    "# Define a function to remove emojis\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\" \n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        \"\\U000024C2-\\U0001F251\" \n",
    "        \"]+\", \n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Apply the function to the 'Message' column\n",
    "df['Message'] = df['Message'].apply(remove_emojis)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_csv('../data/clean_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Labeling for Product, Price, and Location Recognition in UTF-8 Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "      <th>Labeled_Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5328.0</td>\n",
       "      <td>3pcs silicon brush spatulas\\n\\n\\n      \\n     ...</td>\n",
       "      <td>2024-09-20 11:50:02+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5328.jpg</td>\n",
       "      <td>3pcs B-PRODUCT\\nsilicon I-PRODUCT\\nbrush I-PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5327.0</td>\n",
       "      <td>Mandoline Slicer\\n\\n ጊዜ ቆጣቢ ስላይስ ማድረጊያ \\n  ለእጅ...</td>\n",
       "      <td>2024-09-20 08:11:40+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mandoline B-PRODUCT\\nSlicer I-PRODUCT\\nጊዜ O\\nቆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5326.0</td>\n",
       "      <td>Table Desk Edge Guard Strip\\n        High Qual...</td>\n",
       "      <td>2024-09-20 05:23:18+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Table B-PRODUCT\\nDesk I-PRODUCT\\nEdge I-PRODUC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5325.0</td>\n",
       "      <td>Table Desk Edge Guard Strip\\n        High Qual...</td>\n",
       "      <td>2024-09-20 05:21:14+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5325.jpg</td>\n",
       "      <td>Table B-PRODUCT\\nDesk I-PRODUCT\\nEdge I-PRODUC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5323.0</td>\n",
       "      <td>Only baby 3in1 double bottle milk warmer,steri...</td>\n",
       "      <td>2024-09-19 13:54:46+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5323.jpg</td>\n",
       "      <td>Only B-PRODUCT\\nbaby I-PRODUCT\\n3in1 I-PRODUCT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Channel Title    Channel Username      ID  \\\n",
       "5   Sheger online-store  @Shageronlinestore  5328.0   \n",
       "6   Sheger online-store  @Shageronlinestore  5327.0   \n",
       "7   Sheger online-store  @Shageronlinestore  5326.0   \n",
       "8   Sheger online-store  @Shageronlinestore  5325.0   \n",
       "10  Sheger online-store  @Shageronlinestore  5323.0   \n",
       "\n",
       "                                              Message  \\\n",
       "5   3pcs silicon brush spatulas\\n\\n\\n      \\n     ...   \n",
       "6   Mandoline Slicer\\n\\n ጊዜ ቆጣቢ ስላይስ ማድረጊያ \\n  ለእጅ...   \n",
       "7   Table Desk Edge Guard Strip\\n        High Qual...   \n",
       "8   Table Desk Edge Guard Strip\\n        High Qual...   \n",
       "10  Only baby 3in1 double bottle milk warmer,steri...   \n",
       "\n",
       "                         Date                          Media Path  \\\n",
       "5   2024-09-20 11:50:02+00:00  photos/@Shageronlinestore_5328.jpg   \n",
       "6   2024-09-20 08:11:40+00:00                                 NaN   \n",
       "7   2024-09-20 05:23:18+00:00                                 NaN   \n",
       "8   2024-09-20 05:21:14+00:00  photos/@Shageronlinestore_5325.jpg   \n",
       "10  2024-09-19 13:54:46+00:00  photos/@Shageronlinestore_5323.jpg   \n",
       "\n",
       "                                      Labeled_Message  \n",
       "5   3pcs B-PRODUCT\\nsilicon I-PRODUCT\\nbrush I-PRO...  \n",
       "6   Mandoline B-PRODUCT\\nSlicer I-PRODUCT\\nጊዜ O\\nቆ...  \n",
       "7   Table B-PRODUCT\\nDesk I-PRODUCT\\nEdge I-PRODUC...  \n",
       "8   Table B-PRODUCT\\nDesk I-PRODUCT\\nEdge I-PRODUC...  \n",
       "10  Only B-PRODUCT\\nbaby I-PRODUCT\\n3in1 I-PRODUCT...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def label_message_utf8_with_birr(message):\n",
    "    # Check if the message is None or empty\n",
    "    if not isinstance(message, str) or message.strip() == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    # Split the message at the first occurrence of '\\n'\n",
    "    if '\\n' in message:\n",
    "        first_line, remaining_message = message.split('\\n', 1)\n",
    "    else:\n",
    "        first_line, remaining_message = message, \"\"\n",
    "    \n",
    "    labeled_tokens = []\n",
    "    \n",
    "    # Tokenize the first line\n",
    "    first_line_tokens = re.findall(r'\\S+', first_line)\n",
    "    \n",
    "    # Label the first token as B-PRODUCT and the rest as I-PRODUCT\n",
    "    if first_line_tokens:\n",
    "        labeled_tokens.append(f\"{first_line_tokens[0]} B-PRODUCT\")  # First token as B-PRODUCT\n",
    "        for token in first_line_tokens[1:]:\n",
    "            labeled_tokens.append(f\"{token} I-PRODUCT\")  # Remaining tokens as I-PRODUCT\n",
    "    \n",
    "    # Process the remaining message normally\n",
    "    if remaining_message:\n",
    "        lines = remaining_message.split('\\n')\n",
    "        for line in lines:\n",
    "            tokens = re.findall(r'\\S+', line)  # Tokenize each line\n",
    "            \n",
    "            for token in tokens:\n",
    "                # Check if token is a price (e.g., 500 ETB, $100, or ብር)\n",
    "                if re.match(r'^\\d{10,}$', token):\n",
    "                    labeled_tokens.append(f\"{token} O\")  # Label as O for \"other\" or outside of any entity\n",
    "                elif re.match(r'^\\d+(\\.\\d{1,2})?$', token) or 'ETB' in token or 'ዋጋ' in token or '$' in token or 'ብር' in token:\n",
    "                    labeled_tokens.append(f\"{token} I-PRICE\")\n",
    "                # Check if token could be a location (e.g., cities or general location names)\n",
    "                elif any(loc in token for loc in ['Addis Ababa', 'ለቡ', 'ለቡ መዳህኒዓለም', 'መገናኛ', 'ቦሌ', 'ሜክሲኮ']):\n",
    "                    labeled_tokens.append(f\"{token} I-LOC\")\n",
    "                # Assume other tokens are part of a product name or general text\n",
    "                else:\n",
    "                    labeled_tokens.append(f\"{token} O\")\n",
    "    \n",
    "    return \"\\n\".join(labeled_tokens)\n",
    "\n",
    "# Apply the updated function to the non-null messages\n",
    "df['Labeled_Message'] = df['Message'].apply(lambda x: label_message_utf8_with_birr(x) if x is not None else \"\")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated labeled dataset to a file in CoNLL format\n",
    "labeled_data_birr_path = 'labeled_telegram_product_price_location.txt-'\n",
    "with open(labeled_data_birr_path, 'w', encoding='utf-8') as f:\n",
    "    for index, row in df.iterrows():\n",
    "        f.write(f\"{row['Labeled_Message']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories = {\n",
    "#     'kids': [\n",
    "#         'toy', 'children', 'kids', 'መጫወቻ', 'play', 'games', 'fun', 'educational', \n",
    "#         'puzzle', 'doll', 'action figure', 'stuffed animal', 'arts and crafts', \n",
    "#         'books', 'outdoor toys', 'building blocks', 'baby', 'toddler', 'Baby',\n",
    "#         'መጫወቻዎች'\n",
    "#     ],\n",
    "#     'men': [\n",
    "#         'men', 'grooming', 'shaving', 'beard', 'razor', 'aftershave', \n",
    "#         'scent', 'deodorant', 'grooming kit', 'haircut', 'fashion', 'suits', \n",
    "#         'wallet', 'watch', 'accessories', 'fitness', 'shoes', \n",
    "#         'አስተካክል', 'የብርሃን ዕቃዎች'\n",
    "#     ],\n",
    "#     'women': [\n",
    "#         'women', 'makeup', 'hair dryer', 'lipstick', 'foundation', 'mascara', \n",
    "#         'skincare', 'nails', 'jewelry', 'dresses', 'handbags', 'accessories', \n",
    "#         'fashion', 'shoes', 'perfume', 'hairstyle', 'wellness', 'beauty', 'style','Hair Drye',\n",
    "#         'እንቅስቃሴ', 'የፀጉር እቃዎች', 'የውበት እቃዎች'\n",
    "#     ],\n",
    "#     'sport': [\n",
    "#         'gym', 'GYM','fitness', 'exercise', 'እንቅስቃሴ', 'workout', 'training', 'yoga', \n",
    "#         'running', 'cycling', 'sportswear', 'equipment', 'weights', 'cardio', \n",
    "#         'aerobics', 'team sports', 'outdoor activities', 'athletics', 'health',  'workout', 'sports',\n",
    "#         'ስፖርት', 'የእንቅስቃሴ መሳሪያዎች'\n",
    "#     ],\n",
    "#     'groceries': [\n",
    "#         'food', 'snacks', 'grocery', 'ምግብ', 'produce', 'fruits', 'vegetables', \n",
    "#         'meat', 'dairy', 'bread', 'cereal', 'beverages', 'frozen', 'canned', \n",
    "#         'organic', 'bulk', 'condiments', 'spices', 'snack bars', 'breakfast', \n",
    "#         'እንቁላል', 'ወተር', 'የምግብ እቃዎች'\n",
    "#     ],\n",
    "#     'accessories': [\n",
    "#         'jewelry', 'bags', 'accessory', 'ቀለበት', 'belts', 'hats', 'scarves', \n",
    "#         'sunglasses', 'watches', 'hair accessories', 'wallets', 'phone cases', \n",
    "#         'keychains', 'pins', 'brooches', 'fashion', 'style', 'gifts', 'decor', 'የልብስ መቶከሻ\\n\\n',\n",
    "#         'የመልክዕ እቃዎች', 'የምታወቅ እቃዎች','Anti-theft ',' Earbuds','PowerBank','Grip Tape','humidifier'\n",
    "#     ],\n",
    "#     'health': [\n",
    "#         'health', 'ጤና', 'wellness', 'nutrition', 'vitamins', 'supplements', \n",
    "#         'exercise', 'fitness', 'mental health', 'meditation', 'stress relief', \n",
    "#         'doctor', 'check-up', 'first aid', 'hygiene', 'immune system', 'balance', \n",
    "#         'self-care', 'አንደኛ ጤና', 'የጤና እቃዎች','pulse'\n",
    "#     ],\n",
    "#     'household': [\n",
    "#         'cleaning', 'furniture', 'decor', 'appliances', 'utensils', 'kitchen', \n",
    "#         'bathroom', 'laundry', 'storage', 'organization', 'home improvement', 'pan', \n",
    "#         'gardening', 'tools', 'supplies', 'safety', 'maintenance', 'pets', 'spatulas','Kitchen','Mop',\n",
    "#         'spatulas\\n\\n','nለኪችንዎ','home', 'comfort', 'ቤት', 'የቤት እቃዎች', 'እንቅስቃሴ','bottle','ፔርሙስ','knife',\n",
    "#         'Glass','የላዛኛ','stove','Ironing Board','Slicer','BLENDER','MULTIFUNCTIONAL BLENDER','Toilet Brush',\n",
    "#         'የቢላ ስብስብ','ቢላ','Oven','fridge', 'መጥበሻ','Toilet','Mob','cookware','Blender','KITCHENWARE','ምንጣፍ','Tablemats'\n",
    "#     ]\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_message_utf8_with_birr(message):\n",
    "    tokens = re.findall(r'\\S+', message)  # Tokenize while considering non-ASCII characters\n",
    "    labeled_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        # Check if token is a price (e.g., 500 ETB, $100, or ብር)\n",
    "        \n",
    "        if re.match(r'^\\d{10,}$', token):\n",
    "            labeled_tokens.append(f\"{token} O\")  # Label as O for \"other\" or outside of any entity\n",
    "        elif re.match(r'^\\d+(\\.\\d{1,2})?$', token) or 'ETB' in token or '$' in token or 'ብር' in token:\n",
    "            labeled_tokens.append(f\"{token} I-PRICE\")\n",
    "        \n",
    "        # Check if token could be a location (e.g., cities or general location names)\n",
    "        elif any(loc in token for loc in ['Addis Ababa', 'ለቡ', 'ለቡ  መዳህኒዓለም', 'መገናኛ','ቦሌ','ሜክሲኮ']):\n",
    "            labeled_tokens.append(f\"{token} I-LOC\")\n",
    "        \n",
    "        elif any(loc in token for loc in ['💥']):\n",
    "            labeled_tokens.append(f\"{token} B-Product\")\n",
    "        \n",
    "        # Assume other tokens are part of a product name (this can be refined)\n",
    "        else:\n",
    "            labeled_tokens.append(f\"{token} O\")\n",
    "    \n",
    "    return \"\\n\".join(labeled_tokens)\n",
    "\n",
    "# Apply the updated function to the non-null messages\n",
    "df['Labeled_Message'] = df['Message'].apply(label_message_utf8_with_birr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated labeled dataset to a file in CoNLL format\n",
    "labeled_data_birr_path = 'labeled_telegram_data_price_product_location_birr.txt'\n",
    "with open(labeled_data_birr_path, 'w', encoding='utf-8') as f:\n",
    "    for index, row in df.iterrows():\n",
    "        f.write(f\"{row['Labeled_Message']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/repos/fa/39/fa39c3e7e2b904627c4b398a1d015cbbe87073c00877f07ebfe52832984dd391/cfc8146abe2a0488e9e2a0c56de7952f7c11ab059eca145a0a727afce0db2865?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27sentencepiece.bpe.model%3B+filename%3D%22sentencepiece.bpe.model%22%3B&Expires=1727803536&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNzgwMzUzNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9mYS8zOS9mYTM5YzNlN2UyYjkwNDYyN2M0YjM5OGExZDAxNWNiYmU4NzA3M2MwMDg3N2YwN2ViZmU1MjgzMjk4NGRkMzkxL2NmYzgxNDZhYmUyYTA0ODhlOWUyYTBjNTZkZTc5NTJmN2MxMWFiMDU5ZWNhMTQ1YTBhNzI3YWZjZTBkYjI4NjU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=MMBmY25%7EUDV5tyCxEBk-HFgvYzwv3eSLOgFUrL6hPhxoykPcUUdUl%7El1Cg%7E%7Etu7EN26WkLtxpqvqgKWL2n0i51bFb7sFdPLqeah%7EkOmZEYXisGDgApy-1HZTglBFegzirNGWnbmhZt4OSXrlUmWdIFrfOp9jbs9zjodBThHVFhX-FpVqhsaTaZFZlRiEVV3NAV0IFSIUQLiYee1F6IwtM1TqEdsOi1hRgkIz42V464L8iQw-M%7EvYd2g7zUKkPmndg5bdwZZhcEC9OhiVabXgfaIZOmp8evNJP7wysWKTCtWZe1jAy5dTJ%7EvUJD%7EUuOfJOFQaC4ZBzNbHHkemQ8K7cA__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\n requires the protobuf library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Telegram-EthioMart-Entity-Extraction\\venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:1452\u001b[0m, in \u001b[0;36mTikTokenConverter.extract_vocab_merges_from_model\u001b[1;34m(self, tiktoken_url)\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1452\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtiktoken\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_tiktoken_bpe\n\u001b[0;32m   1453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tiktoken'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Telegram-EthioMart-Entity-Extraction\\venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:1592\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[1;34m(transformer_tokenizer, from_tiktoken)\u001b[0m\n\u001b[0;32m   1588\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting from Tiktoken\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTikTokenConverter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1591\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madditional_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 1592\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Telegram-EthioMart-Entity-Extraction\\venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:1489\u001b[0m, in \u001b[0;36mTikTokenConverter.converted\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconverted\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tokenizer:\n\u001b[1;32m-> 1489\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1490\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39mpre_tokenizer \u001b[38;5;241m=\u001b[39m pre_tokenizers\u001b[38;5;241m.\u001b[39mSequence(\n\u001b[0;32m   1491\u001b[0m         [\n\u001b[0;32m   1492\u001b[0m             pre_tokenizers\u001b[38;5;241m.\u001b[39mSplit(Regex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpattern), behavior\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misolated\u001b[39m\u001b[38;5;124m\"\u001b[39m, invert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1493\u001b[0m             pre_tokenizers\u001b[38;5;241m.\u001b[39mByteLevel(add_prefix_space\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space, use_regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1494\u001b[0m         ]\n\u001b[0;32m   1495\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Telegram-EthioMart-Entity-Extraction\\venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:1482\u001b[0m, in \u001b[0;36mTikTokenConverter.tokenizer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenizer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 1482\u001b[0m     vocab_scores, merges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_vocab_merges_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1483\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m Tokenizer(BPE(vocab_scores, merges, fuse_unk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Telegram-EthioMart-Entity-Extraction\\venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:1454\u001b[0m, in \u001b[0;36mTikTokenConverter.extract_vocab_merges_from_model\u001b[1;34m(self, tiktoken_url)\u001b[0m\n\u001b[0;32m   1453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m-> 1454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tiktoken` is required to read a `tiktoken` file. Install it with \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tiktoken`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1456\u001b[0m     )\n\u001b[0;32m   1458\u001b[0m bpe_ranks \u001b[38;5;241m=\u001b[39m load_tiktoken_bpe(tiktoken_url)\n",
      "\u001b[1;31mValueError\u001b[0m: `tiktoken` is required to read a `tiktoken` file. Install it with `pip install tiktoken`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Telegram-EthioMart-Entity-Extraction\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2450\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[1;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2449\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2450\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m import_protobuf_decode_error():\n",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Telegram-EthioMart-Entity-Extraction\\venv\\Lib\\site-packages\\transformers\\models\\xlm_roberta\\tokenization_xlm_roberta_fast.py:108\u001b[0m, in \u001b[0;36mXLMRobertaTokenizerFast.__init__\u001b[1;34m(self, vocab_file, tokenizer_file, bos_token, eos_token, sep_token, cls_token, unk_token, pad_token, mask_token, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m mask_token \u001b[38;5;241m=\u001b[39m AddedToken(mask_token, lstrip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rstrip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask_token, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m mask_token\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcls_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcls_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43munk_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munk_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_file \u001b[38;5;241m=\u001b[39m vocab_file\n",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Telegram-EthioMart-Entity-Extraction\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:138\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madditional_special_tokens \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditional_special_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[1;32m--> 138\u001b[0m fast_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_slow_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_tiktoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m slow_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Telegram-EthioMart-Entity-Extraction\\venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:1594\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[1;34m(transformer_tokenizer, from_tiktoken)\u001b[0m\n\u001b[0;32m   1593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m-> 1594\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1595\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1596\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith a SentencePiece tokenizer.model file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1597\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently available slow->fast convertors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(SLOW_TO_FAST_CONVERTERS\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1598\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForTokenClassification\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m----> 3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmasakhane/afroxlmr-large-ner-masakhaner-1.0_2.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForTokenClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmasakhane/afroxlmr-large-ner-masakhaner-1.0_2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m nlp \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Telegram-EthioMart-Entity-Extraction\\venv\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:907\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    905\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist or is not currently imported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    906\u001b[0m         )\n\u001b[1;32m--> 907\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, EncoderDecoderConfig):\n",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Telegram-EthioMart-Entity-Extraction\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2216\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2214\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2224\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2225\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2227\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2228\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Telegram-EthioMart-Entity-Extraction\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2451\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[1;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2449\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2450\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39minit_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_kwargs)\n\u001b[1;32m-> 2451\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mimport_protobuf_decode_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   2452\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load tokenizer model from SPM, loading from TikToken will be attempted instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Google protobuf error: Tried to load SPM model with non-SPM vocab file).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2455\u001b[0m     )\n\u001b[0;32m   2456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wubeshet.abera\\Projects\\Ten-Academy\\Telegram-EthioMart-Entity-Extraction\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:87\u001b[0m, in \u001b[0;36mimport_protobuf_decode_error\u001b[1;34m(error_message)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DecodeError\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(PROTOBUF_IMPORT_ERROR\u001b[38;5;241m.\u001b[39mformat(error_message))\n",
      "\u001b[1;31mImportError\u001b[0m: \n requires the protobuf library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"masakhane/afroxlmr-large-ner-masakhaner-1.0_2.0\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"masakhane/afroxlmr-large-ner-masakhaner-1.0_2.0\")\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "example = df['Message'][10]\n",
    "ner_results = nlp(example)\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'💥Only baby 3in1 double bottle milk warmer,sterilizer,food steamer\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 ዋጋ:-3000ብር✅\\n\\n❌ውስን ፍሬ ነው ያለው\\n\\n🏢 አድራሻ\\xa0 ቁ.1👉 ስሪ ኤም ሲቲ ሞል\\xa0 ሁለተኛ ፎቅ ቢሮ ቁ. SL-05A(ከ ሊፍቱ ፊት ለ ፊት)\\n\\n📍ቁ.2 👉ለቡ\\xa0 መዳህኒዓለም ቤተ/ክርስቲያን ፊት ለፊት\\xa0 #ዛም_ሞል 2ኛ ፎቅ ቢሮ ቁጥር.214\\n\\n👍ለቡ\\xa0ቅርንጫፍ📲0973611819\\n\\n\\n\\n\\xa0\\xa0\\xa0\\xa0 💧💧💧💧\\n\\n\\n\\xa0\\xa0\\xa0 📲 0909522840\\n\\xa0\\xa0\\xa0 📲 0923350054\\n\\n🔖\\n💬\\xa0 በTelegram ለማዘዝ ⤵️ ይጠቀሙ\\n@shager_onlinestore\\n\\xa0 \\nለተጨማሪ ማብራሪያ የቴሌግራም ገፃችን⤵️\\nhttps://t.me/Shageronlinestore'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Message'][10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a string contains Amharic characters\n",
    "def is_amharic(message):\n",
    "    return bool(re.search(r'[\\u1200-\\u137F]', message))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify messages\n",
    "def classify_message(message):\n",
    "    if pd.isna(message):  # Check for NaN or None\n",
    "        return 'uncategorized'\n",
    "    \n",
    "    if is_amharic(message):\n",
    "        for category, keywords in categories.items():\n",
    "            if any(keyword in message for keyword in keywords):\n",
    "                return category\n",
    "    else:\n",
    "        for category, keywords in categories.items():\n",
    "            if any(keyword in message.lower() for keyword in keywords):\n",
    "                return category\n",
    "    return 'uncategorized'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Message   Category\n",
      "5     💥3pcs silicon brush spatulas\\n\\n⚡እስከ 260°c ሙቀት...  household\n",
      "6     💥Mandoline Slicer\\n\\n👉 ጊዜ ቆጣቢ ስላይስ ማድረጊያ \\n👉  ...  household\n",
      "7     💥Table Desk Edge Guard Strip\\n       💯 High Qu...        men\n",
      "8     💥Table Desk Edge Guard Strip\\n       💯 High Qu...        men\n",
      "10    💥Only baby 3in1 double bottle milk warmer,ster...       kids\n",
      "...                                                 ...        ...\n",
      "5009  🎯 Kitchen Sticker\\n\\nለኪችንዎ ውበት እጅግ ተመራጭ \\n🔰ውሀ ...  household\n",
      "5010  🎯 3in1 One Step Hair Dryer & Styler \\n\\n👉 ከርል ...      women\n",
      "5011  ✅ Home GYM - X5 slimming vibrator \\n\\n📢📢📢 ታላቅ ...      sport\n",
      "5012  ለጤናችን-Health & Personal Care\\n\\n📍FingerTip Pul...       kids\n",
      "5013  #Finger_tip_pulse_oximeter\\n       #በተመጣጣኝ_ዋጋ\\...     health\n",
      "\n",
      "[3166 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6692/2163786579.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Category'] = df['Message'].apply(classify_message)\n"
     ]
    }
   ],
   "source": [
    "# Apply classification to the Message column\n",
    "df['Category'] = df['Message'].apply(classify_message)\n",
    "\n",
    "# Display the updated DataFrame with categories\n",
    "print(df[['Message', 'Category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\n",
      "uncategorized    1337\n",
      "household         821\n",
      "kids              473\n",
      "men               174\n",
      "groceries         152\n",
      "health             70\n",
      "women              50\n",
      "sport              45\n",
      "accessories        44\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display counts of unique values in the Category column\n",
    "category_counts = df['Category'].value_counts()\n",
    "print(category_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5328</td>\n",
       "      <td>💥3pcs silicon brush spatulas\\n\\n⚡እስከ 260°c ሙቀት...</td>\n",
       "      <td>2024-09-20 11:50:02+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5328.jpg</td>\n",
       "      <td>household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5327</td>\n",
       "      <td>💥Mandoline Slicer\\n\\n👉 ጊዜ ቆጣቢ ስላይስ ማድረጊያ \\n👉  ...</td>\n",
       "      <td>2024-09-20 08:11:40+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5326</td>\n",
       "      <td>💥Table Desk Edge Guard Strip\\n       💯 High Qu...</td>\n",
       "      <td>2024-09-20 05:23:18+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5325</td>\n",
       "      <td>💥Table Desk Edge Guard Strip\\n       💯 High Qu...</td>\n",
       "      <td>2024-09-20 05:21:14+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5325.jpg</td>\n",
       "      <td>men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5323</td>\n",
       "      <td>💥Only baby 3in1 double bottle milk warmer,ster...</td>\n",
       "      <td>2024-09-19 13:54:46+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5323.jpg</td>\n",
       "      <td>kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5142</td>\n",
       "      <td>🌟WINNING STAR® 2in1 MULTIFUNCTIONAL BLENDER\\n\\...</td>\n",
       "      <td>2024-08-29 09:12:06+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5142.jpg</td>\n",
       "      <td>kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5141</td>\n",
       "      <td>🥂3.6L Glass dispenser jar with Bamboo stand\\n\\...</td>\n",
       "      <td>2024-08-29 06:02:13+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5140</td>\n",
       "      <td>🥂3.6L Glass dispenser jar with Bamboo stand\\n\\...</td>\n",
       "      <td>2024-08-29 06:01:02+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5140.jpg</td>\n",
       "      <td>household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5139</td>\n",
       "      <td>💥44CM HAOCHU® CERAMIC PIZZA PAN\\n\\n⚡️ለቤትና ለሬስቶ...</td>\n",
       "      <td>2024-08-28 18:38:44+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5139.jpg</td>\n",
       "      <td>household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5138</td>\n",
       "      <td>💥Silver Crest® touch technology electric stove...</td>\n",
       "      <td>2024-08-28 14:11:54+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5138.jpg</td>\n",
       "      <td>household</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Channel Title    Channel Username    ID  \\\n",
       "5    Sheger online-store  @Shageronlinestore  5328   \n",
       "6    Sheger online-store  @Shageronlinestore  5327   \n",
       "7    Sheger online-store  @Shageronlinestore  5326   \n",
       "8    Sheger online-store  @Shageronlinestore  5325   \n",
       "10   Sheger online-store  @Shageronlinestore  5323   \n",
       "..                   ...                 ...   ...   \n",
       "181  Sheger online-store  @Shageronlinestore  5142   \n",
       "182  Sheger online-store  @Shageronlinestore  5141   \n",
       "183  Sheger online-store  @Shageronlinestore  5140   \n",
       "184  Sheger online-store  @Shageronlinestore  5139   \n",
       "185  Sheger online-store  @Shageronlinestore  5138   \n",
       "\n",
       "                                               Message  \\\n",
       "5    💥3pcs silicon brush spatulas\\n\\n⚡እስከ 260°c ሙቀት...   \n",
       "6    💥Mandoline Slicer\\n\\n👉 ጊዜ ቆጣቢ ስላይስ ማድረጊያ \\n👉  ...   \n",
       "7    💥Table Desk Edge Guard Strip\\n       💯 High Qu...   \n",
       "8    💥Table Desk Edge Guard Strip\\n       💯 High Qu...   \n",
       "10   💥Only baby 3in1 double bottle milk warmer,ster...   \n",
       "..                                                 ...   \n",
       "181  🌟WINNING STAR® 2in1 MULTIFUNCTIONAL BLENDER\\n\\...   \n",
       "182  🥂3.6L Glass dispenser jar with Bamboo stand\\n\\...   \n",
       "183  🥂3.6L Glass dispenser jar with Bamboo stand\\n\\...   \n",
       "184  💥44CM HAOCHU® CERAMIC PIZZA PAN\\n\\n⚡️ለቤትና ለሬስቶ...   \n",
       "185  💥Silver Crest® touch technology electric stove...   \n",
       "\n",
       "                          Date                          Media Path   Category  \n",
       "5    2024-09-20 11:50:02+00:00  photos/@Shageronlinestore_5328.jpg  household  \n",
       "6    2024-09-20 08:11:40+00:00                                 NaN  household  \n",
       "7    2024-09-20 05:23:18+00:00                                 NaN        men  \n",
       "8    2024-09-20 05:21:14+00:00  photos/@Shageronlinestore_5325.jpg        men  \n",
       "10   2024-09-19 13:54:46+00:00  photos/@Shageronlinestore_5323.jpg       kids  \n",
       "..                         ...                                 ...        ...  \n",
       "181  2024-08-29 09:12:06+00:00  photos/@Shageronlinestore_5142.jpg       kids  \n",
       "182  2024-08-29 06:02:13+00:00                                 NaN  household  \n",
       "183  2024-08-29 06:01:02+00:00  photos/@Shageronlinestore_5140.jpg  household  \n",
       "184  2024-08-28 18:38:44+00:00  photos/@Shageronlinestore_5139.jpg  household  \n",
       "185  2024-08-28 14:11:54+00:00  photos/@Shageronlinestore_5138.jpg  household  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wordcloud import WordCloud\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Filter for uncategorized items\n",
    "# uncategorized_items = df[df['Category'] == 'uncategorized']\n",
    "\n",
    "# # Combine all messages into a single string\n",
    "# text = ' '.join(uncategorized_items['Message'])\n",
    "\n",
    "# # Generate the word cloud\n",
    "# wordcloud = WordCloud(width=800, height=400, background_color='white', \n",
    "#                       colormap='viridis', max_words=200).generate(text)\n",
    "\n",
    "# # Display the word cloud\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.imshow(wordcloud, interpolation='bilinear')\n",
    "# plt.axis('off')  # Turn off the axis\n",
    "# plt.title('Word Cloud of Messages for Uncategorized Items')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5284</td>\n",
       "      <td>⭐️💫እንኳን ለመውሊድ በዓል በሰላም አደረሰዎ\\n\\nመልካም በዓል</td>\n",
       "      <td>2024-09-15 08:53:29+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5284.jpg</td>\n",
       "      <td>uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5283</td>\n",
       "      <td>💥 ውድ ደንበኞቻችን ሱቃችን ዛሬ  እሁድ ከ5:00-9:00 ስዓት ክፍት መ...</td>\n",
       "      <td>2024-09-15 07:06:34+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5283.jpg</td>\n",
       "      <td>uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5256</td>\n",
       "      <td>💥ውስን ፍሬ የቀሩን ዕቃዎች\\n🌼🌼.................🌼🌼\\n\\n✨ፈ...</td>\n",
       "      <td>2024-09-10 05:31:03+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5256.jpg</td>\n",
       "      <td>uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5237</td>\n",
       "      <td>🌼🌼........................🌼🌼\\n💥በረፍት ቀንዎ ሱቅ ላይ ...</td>\n",
       "      <td>2024-09-07 16:58:25+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5237.jpg</td>\n",
       "      <td>uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>5206</td>\n",
       "      <td>🌼🌼........................🌼🌼\\n💥Ethereum® Washi...</td>\n",
       "      <td>2024-09-05 08:07:01+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_5206.jpg</td>\n",
       "      <td>uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>4654</td>\n",
       "      <td>💥Painless hair eraser\\n\\n       ዋጋ-500ብር\\n\\n🏢 ...</td>\n",
       "      <td>2024-07-04 07:53:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>4649</td>\n",
       "      <td>👶Kids knitted winter warm hat with scarf🧣\\n\\n⚡...</td>\n",
       "      <td>2024-07-03 14:43:54+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_4649.jpg</td>\n",
       "      <td>uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>4640</td>\n",
       "      <td>❇️ Wall Mounted Phone Holder Charging Stand La...</td>\n",
       "      <td>2024-07-03 07:43:48+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>4639</td>\n",
       "      <td>❇️ Wall Mounted Phone Holder Charging Stand La...</td>\n",
       "      <td>2024-07-03 07:38:21+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_4639.jpg</td>\n",
       "      <td>uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>Sheger online-store</td>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>4638</td>\n",
       "      <td>💥Philips Easy Speed Iron\\n\\n🌟Easy to use\\n🌟Wat...</td>\n",
       "      <td>2024-07-02 19:24:15+00:00</td>\n",
       "      <td>photos/@Shageronlinestore_4638.jpg</td>\n",
       "      <td>uncategorized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Channel Title    Channel Username    ID  \\\n",
       "47   Sheger online-store  @Shageronlinestore  5284   \n",
       "48   Sheger online-store  @Shageronlinestore  5283   \n",
       "72   Sheger online-store  @Shageronlinestore  5256   \n",
       "91   Sheger online-store  @Shageronlinestore  5237   \n",
       "120  Sheger online-store  @Shageronlinestore  5206   \n",
       "..                   ...                 ...   ...   \n",
       "628  Sheger online-store  @Shageronlinestore  4654   \n",
       "633  Sheger online-store  @Shageronlinestore  4649   \n",
       "642  Sheger online-store  @Shageronlinestore  4640   \n",
       "643  Sheger online-store  @Shageronlinestore  4639   \n",
       "644  Sheger online-store  @Shageronlinestore  4638   \n",
       "\n",
       "                                               Message  \\\n",
       "47            ⭐️💫እንኳን ለመውሊድ በዓል በሰላም አደረሰዎ\\n\\nመልካም በዓል   \n",
       "48   💥 ውድ ደንበኞቻችን ሱቃችን ዛሬ  እሁድ ከ5:00-9:00 ስዓት ክፍት መ...   \n",
       "72   💥ውስን ፍሬ የቀሩን ዕቃዎች\\n🌼🌼.................🌼🌼\\n\\n✨ፈ...   \n",
       "91   🌼🌼........................🌼🌼\\n💥በረፍት ቀንዎ ሱቅ ላይ ...   \n",
       "120  🌼🌼........................🌼🌼\\n💥Ethereum® Washi...   \n",
       "..                                                 ...   \n",
       "628  💥Painless hair eraser\\n\\n       ዋጋ-500ብር\\n\\n🏢 ...   \n",
       "633  👶Kids knitted winter warm hat with scarf🧣\\n\\n⚡...   \n",
       "642  ❇️ Wall Mounted Phone Holder Charging Stand La...   \n",
       "643  ❇️ Wall Mounted Phone Holder Charging Stand La...   \n",
       "644  💥Philips Easy Speed Iron\\n\\n🌟Easy to use\\n🌟Wat...   \n",
       "\n",
       "                          Date                          Media Path  \\\n",
       "47   2024-09-15 08:53:29+00:00  photos/@Shageronlinestore_5284.jpg   \n",
       "48   2024-09-15 07:06:34+00:00  photos/@Shageronlinestore_5283.jpg   \n",
       "72   2024-09-10 05:31:03+00:00  photos/@Shageronlinestore_5256.jpg   \n",
       "91   2024-09-07 16:58:25+00:00  photos/@Shageronlinestore_5237.jpg   \n",
       "120  2024-09-05 08:07:01+00:00  photos/@Shageronlinestore_5206.jpg   \n",
       "..                         ...                                 ...   \n",
       "628  2024-07-04 07:53:00+00:00                                 NaN   \n",
       "633  2024-07-03 14:43:54+00:00  photos/@Shageronlinestore_4649.jpg   \n",
       "642  2024-07-03 07:43:48+00:00                                 NaN   \n",
       "643  2024-07-03 07:38:21+00:00  photos/@Shageronlinestore_4639.jpg   \n",
       "644  2024-07-02 19:24:15+00:00  photos/@Shageronlinestore_4638.jpg   \n",
       "\n",
       "          Category  \n",
       "47   uncategorized  \n",
       "48   uncategorized  \n",
       "72   uncategorized  \n",
       "91   uncategorized  \n",
       "120  uncategorized  \n",
       "..             ...  \n",
       "628  uncategorized  \n",
       "633  uncategorized  \n",
       "642  uncategorized  \n",
       "643  uncategorized  \n",
       "644  uncategorized  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncategorized_items = df[df['Category'] == 'uncategorized']\n",
    "uncategorized_items.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('labeled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncategorized_items.to_csv('uncategorized_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
